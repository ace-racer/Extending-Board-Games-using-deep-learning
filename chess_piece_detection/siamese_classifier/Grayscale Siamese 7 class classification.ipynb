{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import product, combinations\n",
    "import math\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Conv2D, Lambda, average, Dense, Flatten,MaxPooling2D, BatchNormalization, Dropout, Activation, Subtract, subtract\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (70, 70)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "\t# compute the median of the single channel pixel intensities\n",
    "\tv = np.median(image)\n",
    " \n",
    "\t# apply automatic Canny edge detection using the computed median\n",
    "\tlower = int(max(0, (1.0 - sigma) * v))\n",
    "\tupper = int(min(255, (1.0 + sigma) * v))\n",
    "\tedged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "\t# return the edged image\n",
    "\treturn edged\n",
    "\n",
    "def process_image(image_location):\n",
    "    \"\"\"\n",
    "        Given the image location, process the image\n",
    "    \"\"\"\n",
    "    # print(image_location)\n",
    "    \n",
    "    image = cv2.imread(image_location)\n",
    "    \n",
    "    if image.shape[0] != IMAGE_SIZE[0] or image.shape[1] != IMAGE_SIZE[1]:\n",
    "        # print(\"Resizing the image: {0}\".format(image_location))\n",
    "        resized_image = cv2.resize(image, IMAGE_SIZE, interpolation = cv2.INTER_AREA)\n",
    "    else:\n",
    "        resized_image = image\n",
    "    \n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edges = auto_canny(gray)\n",
    "    # print(edges.shape)\n",
    "    \n",
    "    \n",
    "    # assert(denoised != edges)\n",
    "    weighted_sum = cv2.addWeighted(gray, 0.7, edges, 0.3, 0)\n",
    "    weighted_sum = weighted_sum[..., np.newaxis]\n",
    "       \n",
    "    return weighted_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 70, 1)\n",
      "19042177\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 70, 70, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 70, 70, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 1024)         19041152    input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 1024)         0           sequential_3[1][0]               \n",
      "                                                                 sequential_3[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1025        subtract_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 19,042,177\n",
      "Trainable params: 19,041,729\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initial code from: https://sorenbouma.github.io/blog/oneshot/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = *IMAGE_SIZE, 1\n",
    "print(input_shape)\n",
    "\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(32,(5,5),input_shape=input_shape, kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(64,(4,4), kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(128,(4,4), kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dropout(0.4))\n",
    "convnet.add(Dense(1024,activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "#merge two encoded inputs with the average\n",
    "both = subtract([encoded_l,encoded_r])\n",
    "# both = K.abs(both)\n",
    "# both = Dense(256, activation='relu')(both)\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "\n",
    "optimizer = Adam(0.0005)\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(siamese_net.count_params())\n",
    "print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#samples_per_type = {\"b\": 30, \"n\": 25, \"k\": 25, \"p\": 35, \"q\": 25, \"r\": 35}\n",
    "# samples_per_type = {\"b\": 3, \"n\": 2, \"k\": 2, \"p\": 3, \"q\": 2, \"r\": 3, \"empty\": 4}\n",
    "type_locations = {\"b\": [\"bb\", \"wb\"], \"n\": [\"bn\", \"wn\"], \"k\": [\"bk\", \"wk\"], \"p\": [\"bp\", \"wp\"], \"q\": [\"bq\", \"wq\"], \"r\": [\"br\", \"wr\"], \"empty\": [\"empty\"]}\n",
    "\n",
    "CHECKPOINTS_LOCATION = \"weights\"\n",
    "LOGS_LOCATION = \"logs\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "\n",
    "if not os.path.exists(CHECKPOINTS_LOCATION):\n",
    "    os.makedirs(CHECKPOINTS_LOCATION)\n",
    "\n",
    "if not os.path.exists(LOGS_LOCATION):\n",
    "    os.makedirs(LOGS_LOCATION)\n",
    "\n",
    "def generate_paired_instances_by_ratio(folder_location, total_instances = 6000, different_records_ratio = 0.5):\n",
    "    \n",
    "    data = []\n",
    "    label_values = []\n",
    "    for type_name in type_locations:\n",
    "        for folder_name in type_locations[type_name]:\n",
    "            piece_type_folder = os.path.join(folder_location, folder_name)\n",
    "            for f in (os.listdir(piece_type_folder)):\n",
    "                if f.endswith(\".jpg\"):\n",
    "                    img_file_loc = os.path.join(piece_type_folder, f)\n",
    "                    data.append(img_file_loc)\n",
    "                    label_values.append(type_name)\n",
    "    \n",
    "    num_categories = len(type_locations)\n",
    "    print(\"Num categories: \" + str(num_categories))\n",
    "\n",
    "    # Get the counts of the individual labels\n",
    "    label_counts = Counter(label_values)\n",
    "    \n",
    "    # Get the label indices in the original data read from the file\n",
    "    label_indices = defaultdict(list)\n",
    "    for itr, val in enumerate(label_values):\n",
    "        label_indices[val].append(itr)\n",
    "    \n",
    "    num_same_items_per_category = int(math.ceil(np.sqrt((( 1- different_records_ratio ) * total_instances) / num_categories)))\n",
    "    num_different_items_per_category = int(math.ceil(np.sqrt((2 * different_records_ratio * total_instances)/(num_categories * (num_categories - 1)))))\n",
    "    print(\"Num same items per category: \" + str(num_same_items_per_category))\n",
    "    print(\"Num different items per category: \" + str(num_different_items_per_category))\n",
    "\n",
    "    most_common_categories = [x for x, _ in label_counts.most_common(num_categories)]\n",
    "    print(\"Most common categories...\")\n",
    "    print(most_common_categories)\n",
    "    \n",
    "    pairwise_indices_same_items = []\n",
    "    for label in most_common_categories:\n",
    "        required_indices = label_indices[label][:num_same_items_per_category]\n",
    "        similar_item_index_pairs = list(product(required_indices, required_indices))\n",
    "        pairwise_indices_same_items.extend(similar_item_index_pairs)\n",
    "\n",
    "    pairwise_indices_different_items = []\n",
    "    category_pairs = combinations(most_common_categories, 2)\n",
    "\n",
    "    for cat1, cat2 in category_pairs:\n",
    "        category1_indices = label_indices[cat1][:num_different_items_per_category]\n",
    "        category2_indices = label_indices[cat2][:num_different_items_per_category]\n",
    "        different_items_index_pairs = list(product(category1_indices, category2_indices))\n",
    "        pairwise_indices_different_items.extend(different_items_index_pairs)\n",
    "\n",
    "    print(\"Num same category pairs: \" + str(len(pairwise_indices_same_items)))\n",
    "    print(\"Num different category pairs: \" + str(len(pairwise_indices_different_items)))\n",
    "\n",
    "    instances_with_labels = []\n",
    "    for idx1, idx2 in pairwise_indices_same_items:\n",
    "        label = 1\n",
    "        \n",
    "        img1 = process_image(data[idx1])\n",
    "        img2 = process_image(data[idx2])\n",
    "        \n",
    "        instances_with_labels.append((img1, img2, label))\n",
    "\n",
    "    for idx1, idx2 in pairwise_indices_different_items:\n",
    "        label = 0\n",
    "\n",
    "        img1 = process_image(data[idx1])\n",
    "        img2 = process_image(data[idx2])\n",
    "\n",
    "        instances_with_labels.append((img1, img2, label))\n",
    "\n",
    "    random.shuffle(instances_with_labels)\n",
    "    instances = np.array([[x[0], x[1]] for x in instances_with_labels])\n",
    "    labels = np.array([x[2] for x in instances_with_labels])\n",
    "\n",
    "    return instances, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num categories: 7\n",
      "Num same items per category: 3\n",
      "Num different items per category: 2\n",
      "Most common categories...\n",
      "['empty', 'p', 'b', 'n', 'q', 'r', 'k']\n",
      "Num same category pairs: 63\n",
      "Num different category pairs: 84\n",
      "(147, 2, 70, 70, 1)\n",
      "(147,)\n",
      "Num categories: 7\n",
      "Num same items per category: 2\n",
      "Num different items per category: 2\n",
      "Most common categories...\n",
      "['p', 'k', 'n', 'r', 'b', 'q', 'empty']\n",
      "Num same category pairs: 28\n",
      "Num different category pairs: 84\n",
      "(147, 2, 70, 70, 1)\n",
      "(112, 2, 70, 70, 1)\n",
      "(147,)\n",
      "(112,)\n",
      "(147, 70, 70, 1)\n",
      "(147, 70, 70, 1)\n",
      "Train on 147 samples, validate on 112 samples\n",
      "Epoch 1/50\n",
      "147/147 [==============================] - 19s 128ms/step - loss: 4.3858 - acc: 0.6735 - val_loss: 7.4224 - val_acc: 0.5179\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.51786, saving model to weights\\siamese_7_class.hdf5\n",
      "Epoch 2/50\n",
      "147/147 [==============================] - 17s 116ms/step - loss: 4.7018 - acc: 0.7279 - val_loss: 9.4089 - val_acc: 0.4375\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.51786\n",
      "Epoch 3/50\n",
      "147/147 [==============================] - 17s 115ms/step - loss: 3.3726 - acc: 0.7891 - val_loss: 7.8527 - val_acc: 0.5089\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.51786\n",
      "Epoch 4/50\n",
      "147/147 [==============================] - 17s 118ms/step - loss: 2.6932 - acc: 0.8639 - val_loss: 7.8286 - val_acc: 0.5179\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.51786\n",
      "Epoch 5/50\n",
      " 32/147 [=====>........................] - ETA: 9s - loss: 2.8070 - acc: 0.8438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6a0098e85690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mX_test_instances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX_test_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_right\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2670\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2672\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2654\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2655\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# change as required\n",
    "IMAGES_LOCATION = \"H:\\\\AR-ExtendingOnlineGames\\\\data\\\\chess_pieces_data\\\\Chess ID Public Data\"\n",
    "\n",
    "X_train_original = []\n",
    "y_train_original = []\n",
    "\n",
    "\n",
    "training_images = os.path.join(IMAGES_LOCATION, \"train\")\n",
    "\n",
    "X_train_original, y_train_original = generate_paired_instances_by_ratio(training_images, 100)\n",
    "\n",
    "X_train_original = np.array(X_train_original)\n",
    "y_train_original = np.array(y_train_original)\n",
    "\n",
    "print(X_train_original.shape)\n",
    "print(y_train_original.shape)\n",
    "\n",
    "# split into train and validation splits\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_original, y_train_original, test_size=0.25, random_state=42, stratify = y_train_original)\n",
    "\n",
    "X_train = X_train_original\n",
    "y_train = y_train_original\n",
    "\n",
    "test_images = os.path.join(IMAGES_LOCATION, \"test\")\n",
    "X_test, y_test = generate_paired_instances_by_ratio(test_images, 50)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_train_left = X_train[:, 0, ...]\n",
    "X_train_right = X_train[:, 1, ...]\n",
    "print(X_train_left.shape)\n",
    "print(X_train_right.shape)\n",
    "\n",
    "X_test_left = X_test[:, 0, ...]\n",
    "X_test_right = X_test[:, 1, ...]\n",
    "\n",
    "\n",
    "filepath = os.path.join(CHECKPOINTS_LOCATION, \"siamese_7_class.hdf5\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=10, verbose=1, mode='max')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=LOGS_LOCATION, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, tensorboard]\n",
    "\n",
    "\n",
    "model = siamese_net\n",
    "X_train_instances = [X_train_left, X_train_right]\n",
    "X_test_instances = [X_test_left, X_test_right]\n",
    "\n",
    "hist = model.fit(X_train_instances, y_train, shuffle=True, batch_size=BATCH_SIZE,epochs=NUM_EPOCHS, verbose=1, validation_data=(X_test_instances, y_test), callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
