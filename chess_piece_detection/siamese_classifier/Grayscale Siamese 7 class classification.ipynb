{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import product, combinations\n",
    "import math\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Conv2D, Lambda, average, Dense, Flatten,MaxPooling2D, BatchNormalization, Dropout, Activation, Subtract, subtract\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (70, 70)\n",
    "\n",
    "\n",
    "def process_image(image_location):\n",
    "    \"\"\"\n",
    "        Given the image location, process the image\n",
    "    \"\"\"\n",
    "    \n",
    "    image = cv2.imread(image_location)\n",
    "    \n",
    "    if image.shape[0] != IMAGE_SIZE[0] or image.shape[1] != IMAGE_SIZE[1]:\n",
    "        # print(\"Resizing the image: {0}\".format(image_location))\n",
    "        resized_image = cv2.resize(image, IMAGE_SIZE, interpolation = cv2.INTER_AREA)\n",
    "    else:\n",
    "        resized_image = image\n",
    "    \n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edges = auto_canny(gray)\n",
    "    # print(edges.shape)\n",
    "    \n",
    "    \n",
    "    # assert(denoised != edges)\n",
    "    weighted_sum = cv2.addWeighted(gray, 0.8, edges, 0.2, 0)\n",
    "    weighted_sum = weighted_sum[..., np.newaxis]\n",
    "       \n",
    "    return weighted_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 70, 1)\n",
      "19042177\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 70, 70, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 70, 70, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1024)         19041152    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 1024)         0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1025        subtract_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 19,042,177\n",
      "Trainable params: 19,041,729\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initial code from: https://sorenbouma.github.io/blog/oneshot/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = *IMAGE_SIZE, 1\n",
    "print(input_shape)\n",
    "\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "\n",
    "convnet.add(Conv2D(32,(5,5),input_shape=input_shape, kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(64,(4,4), kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(MaxPooling2D())\n",
    "\n",
    "convnet.add(Conv2D(128,(4,4), kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Activation('relu'))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dropout(0.4))\n",
    "convnet.add(Dense(1024,activation=\"relu\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "#merge two encoded inputs with the average\n",
    "both = subtract([encoded_l,encoded_r])\n",
    "# both = K.abs(both)\n",
    "# both = Dense(256, activation='relu')(both)\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "\n",
    "optimizer = Adam(0.0005)\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(siamese_net.count_params())\n",
    "print(siamese_net.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#samples_per_type = {\"b\": 30, \"n\": 25, \"k\": 25, \"p\": 35, \"q\": 25, \"r\": 35}\n",
    "# samples_per_type = {\"b\": 3, \"n\": 2, \"k\": 2, \"p\": 3, \"q\": 2, \"r\": 3, \"empty\": 4}\n",
    "type_locations = {\"b\": [\"bb\", \"wb\"], \"n\": [\"bn\", \"wn\"], \"k\": [\"bk\", \"wk\"], \"p\": [\"bp\", \"wp\"], \"q\": [\"bq\", \"wq\"], \"r\": [\"br\", \"wr\"], \"empty\": [\"empty\"]}\n",
    "\n",
    "CHECKPOINTS_LOCATION = \"weights\"\n",
    "LOGS_LOCATION = \"logs\"\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "\n",
    "if not os.path.exists(CHECKPOINTS_LOCATION):\n",
    "    os.makedirs(CHECKPOINTS_LOCATION)\n",
    "\n",
    "if not os.path.exists(LOGS_LOCATION):\n",
    "    os.makedirs(LOGS_LOCATION)\n",
    "\n",
    "def generate_paired_instances_by_ratio(folder_location, total_instances = 6000, different_records_ratio = 0.5):\n",
    "    \n",
    "    data = []\n",
    "    label_values = []\n",
    "    for type_name in type_locations:\n",
    "        for folder_name in type_locations[type_name]:\n",
    "            piece_type_folder = os.path.join(folder_location, folder_name)\n",
    "            for f in (os.listdir(piece_type_folder)):\n",
    "                img_file_loc = os.path.join(piece_type_folder, f)\n",
    "                data.append(img_file_loc)\n",
    "                label_values.append(type_name)\n",
    "    \n",
    "    num_categories = len(type_locations)\n",
    "    print(\"Num categories: \" + str(num_categories))\n",
    "\n",
    "    # Get the counts of the individual labels\n",
    "    label_counts = Counter(label_values)\n",
    "    \n",
    "    # Get the label indices in the original data read from the file\n",
    "    label_indices = defaultdict(list)\n",
    "    for itr, val in enumerate(label_values):\n",
    "        label_indices[val].append(itr)\n",
    "    \n",
    "    num_same_items_per_category = int(math.ceil(np.sqrt((( 1- different_records_ratio ) * total_instances) / num_categories)))\n",
    "    num_different_items_per_category = int(math.ceil(np.sqrt((2 * different_records_ratio * total_instances)/(num_categories * (num_categories - 1)))))\n",
    "    print(\"Num same items per category: \" + str(num_same_items_per_category))\n",
    "    print(\"Num different items per category: \" + str(num_different_items_per_category))\n",
    "\n",
    "    most_common_categories = [x for x, _ in label_counts.most_common(num_categories)]\n",
    "    print(\"Most common categories...\")\n",
    "    print(most_common_categories)\n",
    "    \n",
    "    pairwise_indices_same_items = []\n",
    "    for label in most_common_categories:\n",
    "        required_indices = label_indices[label][:num_same_items_per_category]\n",
    "        similar_item_index_pairs = list(product(required_indices, required_indices))\n",
    "        pairwise_indices_same_items.extend(similar_item_index_pairs)\n",
    "\n",
    "    pairwise_indices_different_items = []\n",
    "    category_pairs = combinations(most_common_categories, 2)\n",
    "\n",
    "    for cat1, cat2 in category_pairs:\n",
    "        category1_indices = label_indices[cat1][:num_different_items_per_category]\n",
    "        category2_indices = label_indices[cat2][:num_different_items_per_category]\n",
    "        different_items_index_pairs = list(product(category1_indices, category2_indices))\n",
    "        pairwise_indices_different_items.extend(different_items_index_pairs)\n",
    "\n",
    "    print(\"Num same category pairs: \" + str(len(pairwise_indices_same_items)))\n",
    "    print(\"Num different category pairs: \" + str(len(pairwise_indices_different_items)))\n",
    "\n",
    "    instances_with_labels = []\n",
    "    for idx1, idx2 in pairwise_indices_same_items:\n",
    "        label = 1\n",
    "        \n",
    "        img1 = process_image(data[idx1])\n",
    "        img2 = process_image(data[idx2])\n",
    "        \n",
    "        instances_with_labels.append((img1, img2, label))\n",
    "\n",
    "    for idx1, idx2 in pairwise_indices_different_items:\n",
    "        label = 0\n",
    "\n",
    "        img1 = process_image(data[idx1])\n",
    "        img2 = process_image(data[idx2])\n",
    "\n",
    "        instances_with_labels.append((img1, img2, label))\n",
    "\n",
    "    random.shuffle(instances_with_labels)\n",
    "    instances = np.array([[x[0], x[1]] for x in instances_with_labels])\n",
    "    labels = np.array([x[2] for x in instances_with_labels])\n",
    "\n",
    "    return instances, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num categories: 7\n",
      "Num same items per category: 3\n",
      "Num different items per category: 2\n",
      "Most common categories...\n",
      "['empty', 'p', 'b', 'n', 'q', 'r', 'k']\n",
      "Num same category pairs: 63\n",
      "Num different category pairs: 84\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6a0098e85690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtraining_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGES_LOCATION\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mX_train_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_paired_instances_by_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mX_train_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_original\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-8726e3b99eec>\u001b[0m in \u001b[0;36mgenerate_paired_instances_by_ratio\u001b[1;34m(folder_location, total_instances, different_records_ratio)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3db58075d1c3>\u001b[0m in \u001b[0;36mprocess_image\u001b[1;34m(image_location)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_location\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m# print(\"Resizing the image: {0}\".format(image_location))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mresized_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# change as required\n",
    "IMAGES_LOCATION = \"H:\\\\AR-ExtendingOnlineGames\\\\data\\\\chess_pieces_data\\\\Chess ID Public Data\"\n",
    "\n",
    "X_train_original = []\n",
    "y_train_original = []\n",
    "\n",
    "\n",
    "training_images = os.path.join(IMAGES_LOCATION, \"train\")\n",
    "\n",
    "X_train_original, y_train_original = generate_paired_instances_by_ratio(training_images, 100)\n",
    "\n",
    "X_train_original = np.array(X_train_original)\n",
    "y_train_original = np.array(y_train_original)\n",
    "\n",
    "print(X_train_original.shape)\n",
    "print(y_train_original.shape)\n",
    "\n",
    "# split into train and validation splits\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_original, y_train_original, test_size=0.25, random_state=42, stratify = y_train_original)\n",
    "\n",
    "X_train = X_train_original\n",
    "y_train = y_train_original\n",
    "\n",
    "test_images = os.path.join(IMAGES_LOCATION, \"test\")\n",
    "X_test, y_test = generate_paired_instances_by_ratio(test_images, 50)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "X_train_left = X_train[:, 0, ...]\n",
    "X_train_right = X_train[:, 1, ...]\n",
    "print(X_train_left.shape)\n",
    "print(X_train_right.shape)\n",
    "\n",
    "X_test_left = X_test[:, 0, ...]\n",
    "X_test_right = X_test[:, 1, ...]\n",
    "\n",
    "\n",
    "filepath = os.path.join(CHECKPOINTS_LOCATION, \"siamese_7_class.hdf5\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0.001, patience=10, verbose=1, mode='max')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=LOGS_LOCATION, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, tensorboard]\n",
    "\n",
    "\n",
    "model = siamese_net\n",
    "X_train_instances = [X_train_left, X_train_right]\n",
    "X_test_instances = [X_test_left, X_test_right]\n",
    "\n",
    "hist = model.fit(X_train_instances, y_train, shuffle=True, batch_size=BATCH_SIZE,epochs=NUM_EPOCHS, verbose=1, validation_data=(X_test_instances, y_test), callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
